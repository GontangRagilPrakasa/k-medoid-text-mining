{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Judul</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Penerapan antarmuka bahasa alami dalam pencari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>System reminder aktifitas akademik dosen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Perancangan Sistem Test Komputerisasi dan Pend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pengolahan Bahasa Alami pada Agen Cerdas Alat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Perancangan dan implementasi system pengenalan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pengembangan Template Media Pembelajaran Berba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Membangun system informasi eksekutif (SIE) den...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Perancangan visualisasi informasi untuk system...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pengembangan Sistem Penilaian Kerja Dosen deng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Perancangan animasi wayang  pendidikan sebagai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Studi Deskriptif: Penyebab dan Bentuk Perilaku...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Judul\n",
       "0   Penerapan antarmuka bahasa alami dalam pencari...\n",
       "1           System reminder aktifitas akademik dosen \n",
       "2   Perancangan Sistem Test Komputerisasi dan Pend...\n",
       "3   Pengolahan Bahasa Alami pada Agen Cerdas Alat ...\n",
       "4   Perancangan dan implementasi system pengenalan...\n",
       "5   Pengembangan Template Media Pembelajaran Berba...\n",
       "6   Membangun system informasi eksekutif (SIE) den...\n",
       "7   Perancangan visualisasi informasi untuk system...\n",
       "8   Pengembangan Sistem Penilaian Kerja Dosen deng...\n",
       "9   Perancangan animasi wayang  pendidikan sebagai...\n",
       "10  Studi Deskriptif: Penyebab dan Bentuk Perilaku..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wb = load_workbook(filename='data-minimalis.xlsx')\n",
    "dataset = pd.DataFrame(wb['Sheet1'].values)\n",
    "dataset.columns = ['Judul']\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sheet_terpilih = wb['Sheet1']\n",
    "# df = pd.DataFrame(sheet_terpilih.values)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns =['judul']\n",
    "# print(df)\n",
    "# df['judul']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Penerapan antarmuka bahasa alami dalam pencarian informasi skripsi pada suatu program studi ',\n",
       " 'System reminder aktifitas akademik dosen ',\n",
       " 'Perancangan Sistem Test Komputerisasi dan Pendukung Keputusan Penerimaan Pegawai',\n",
       " 'Pengolahan Bahasa Alami pada Agen Cerdas Alat Bantu Konsultasi Zakat',\n",
       " 'Perancangan dan implementasi system pengenalan  jenis kulit hewan unutk kerajinan kulit berbasis system cerdas ',\n",
       " 'Pengembangan Template Media Pembelajaran Berbasis Flash',\n",
       " 'Membangun system informasi eksekutif (SIE) dengan menggunakan pendekatan system cerdas ',\n",
       " 'Perancangan visualisasi informasi untuk system evaluasi guru ',\n",
       " 'Pengembangan Sistem Penilaian Kerja Dosen dengan Aspek IKD dan SKP 2014 Berbasis Online',\n",
       " 'Perancangan animasi wayang  pendidikan sebagai pengembangan media edukasi sekolah ',\n",
       " 'Studi Deskriptif: Penyebab dan Bentuk Perilaku Mencontek pada SMP Muhammadiyah se-Kota Yogyakarta Tahun 2012/2013']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_judul=[]\n",
    "for ai in data['judul']:\n",
    "#     print(ai)\n",
    "    list_judul.append(str(ai))\n",
    "list_judul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf8\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory # Rumus Library\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "import string # Rumus Library\n",
    "import sys # Rumus supaya baca command promp\n",
    "import re\n",
    "\n",
    "stemmer = StemmerFactory().create_stemmer() # Object stemmer\n",
    "remover = StopWordRemoverFactory().create_stop_word_remover() # objek stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['terap antarmuka bahasa alami cari informasi skripsi suatu program studi',\n",
       " 'system reminder aktifitas akademik dosen',\n",
       " 'ancang sistem test komputerisasi dukung putus terima pegawai',\n",
       " 'olah bahasa alami agen cerdas alat bantu konsultasi zakat',\n",
       " 'ancang implementasi system kenal jenis kulit hewan unutk rajin kulit bas system cerdas',\n",
       " 'kembang template media ajar bas flash',\n",
       " 'bangun system informasi eksekutif sie guna dekat system cerdas',\n",
       " 'ancang visualisasi informasi system evaluasi guru',\n",
       " 'kembang sistem nilai kerja dosen aspek ikd skp 2014 bas online',\n",
       " 'ancang animasi wayang didik kembang media edukasi sekolah',\n",
       " 'studi deskriptif sebab bentuk perilaku contek smp muhammadiyah se-kota yogyakarta tahun 2012 2013']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower() # lowercase, bisa semua sama\n",
    "    text_clean = remover.remove(text) # fungsi hapus stopword dan remover (warna merah) berasal dari objek\n",
    "#     preprocessed_text = text_clean.translate(None, string.punctuation) # fungsi hapus punctiation atau . , ; dll  dan\n",
    "    # text_clean (warna merah) dari variabel atasnya\n",
    "    text_stem = stemmer.stem(text_clean)\n",
    "    return text_stem\n",
    "# preprocess(list_judul[1])\n",
    "pre_judul = []\n",
    "for juduls in list_judul:\n",
    "    pre_judul.append(preprocess(juduls))\n",
    "pre_judul\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['terap antarmuka bahasa alami cari informasi skripsi suatu program studi',\n",
       " 'system reminder aktifitas akademik dosen',\n",
       " 'ancang sistem test komputerisasi dukung putus terima pegawai',\n",
       " 'olah bahasa alami agen cerdas alat bantu konsultasi zakat',\n",
       " 'ancang implementasi system kenal jenis kulit hewan unutk rajin kulit bas system cerdas',\n",
       " 'kembang template media ajar bas flash',\n",
       " 'bangun system informasi eksekutif sie guna dekat system cerdas',\n",
       " 'ancang visualisasi informasi system evaluasi guru',\n",
       " 'kembang sistem nilai kerja dosen aspek ikd skp 2014 bas online',\n",
       " 'ancang animasi wayang didik kembang media edukasi sekolah',\n",
       " 'studi deskriptif sebab bentuk perilaku contek smp muhammadiyah se-kota yogyakarta tahun 2012 2013']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_judul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import numpy.linalg as LA\n",
    "\n",
    "class Engine:\n",
    "    def __init__(self):\n",
    "        self.cosine_score = []\n",
    "        self.train_set = [] #Documents\n",
    "        self.test_set = [] #Query\n",
    "\n",
    "    def addDocument(self, word):\n",
    "        self.train_set.append(word)\n",
    "\n",
    "    def setQuery(self, word):\n",
    "        self.test_set.append(word)\n",
    "\n",
    "    def process_score(self):\n",
    "        stopWords = stopwords.words('english')\n",
    "        vectorizer = CountVectorizer()\n",
    "\n",
    "        transformer = TfidfTransformer()\n",
    "        \n",
    "        trainVectorizerArray = vectorizer.fit_transform(self.train_set).toarray()\n",
    "        testVectorizerArray = vectorizer.transform(self.test_set).toarray()\n",
    "    \n",
    "        cx = lambda a, b : round(np.inner(a, b)/(LA.norm(a)*LA.norm(b)), 3)\n",
    "#         print testVectorizerArray\n",
    "        output = []\n",
    "        for i in range(0,len(testVectorizerArray)):\n",
    "            output.append([])\n",
    "            \n",
    "            \n",
    "        for vector in trainVectorizerArray:\n",
    "            # print vector\n",
    "            u = 0\n",
    "            for testV in testVectorizerArray:\n",
    "                # print testV\n",
    "                cosine = cx(vector, testV)\n",
    "#                 self.cosine_score.append(cosine)\n",
    "                output[u].append(cosine)\n",
    "                u = u + 1\n",
    "        return output\n",
    "        # return testVectorizerArray\n",
    "\n",
    "    def check_tag(self,tag,tags):\n",
    "        # data_tag = tag.split(',')\n",
    "        # data_tags = tags.split(',')\n",
    "        stat = False\n",
    "        if tag in tags:\n",
    "            stat = True\n",
    "\n",
    "        return stat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0, 0.0, 0.0, 0.211, 0.0, 0.0, 0.095, 0.129, 0.0, 0.0, 0.085],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.217, 0.0, 0.27, 0.183, 0.135, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.086, 0.0, 0.0, 0.144, 0.107, 0.125, 0.0],\n",
       " [0.211, 0.0, 0.0, 1.0, 0.081, 0.0, 0.101, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.217, 0.086, 0.081, 1.0, 0.099, 0.366, 0.297, 0.073, 0.086, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.099, 1.0, 0.0, 0.0, 0.246, 0.289, 0.0],\n",
       " [0.095, 0.27, 0.0, 0.101, 0.366, 0.0, 1.0, 0.369, 0.0, 0.0, 0.0],\n",
       " [0.129, 0.183, 0.144, 0.0, 0.297, 0.0, 0.369, 1.0, 0.0, 0.144, 0.0],\n",
       " [0.0, 0.135, 0.107, 0.0, 0.073, 0.246, 0.0, 0.0, 1.0, 0.107, 0.0],\n",
       " [0.0, 0.0, 0.125, 0.0, 0.086, 0.289, 0.0, 0.144, 0.107, 1.0, 0.0],\n",
       " [0.085, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string # Rumus Library\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import sys\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "def stemmerEN(text):\n",
    "    porter = PorterStemmer()\n",
    "    stop = set(stopwords.words('english'))\n",
    "    text = text.lower()\n",
    "    text = [i for i in text.lower().split() if i not in stop]\n",
    "    text = ' '.join(text)\n",
    "    preprocessed_text = text.translate(None, string.punctuation)\n",
    "    text_stem = porter.stem(preprocessed_text)\n",
    "    return text_stem\n",
    "\n",
    "judul = [str(x) for x in pre_judul]\n",
    "\n",
    "\n",
    "uji=pre_judul\n",
    "list_datauji =pre_judul\n",
    "match_tags = []\n",
    "match_tags_full = []\n",
    "match_title = []\n",
    "# target_title=[]\n",
    "# print stemmerEN(\"A bayesian mixture model with linear regression mixing proportions\")\n",
    "\n",
    "engine = Engine()\n",
    "list_dokumen = [str(x) for x in judul]\n",
    "list_datauji = [str(x) for x in list_datauji]\n",
    "for dok in list_dokumen:\n",
    "    engine.addDocument(dok)\n",
    "\n",
    "for doku in list_datauji:\n",
    "    engine.setQuery(doku)\n",
    "    \n",
    "titles_score = engine.process_score()\n",
    "len(titles_score)\n",
    "\n",
    "titles_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def kMedoids(D, k, tmax=100):\n",
    "    # determine dimensions of distance matrix D\n",
    "    m, n = D.shape\n",
    "\n",
    "    if k > n:\n",
    "        raise Exception('too many medoids')\n",
    "\n",
    "    # find a set of valid initial cluster medoid indices since we\n",
    "    # can't seed different clusters with two points at the same location\n",
    "    valid_medoid_inds = set(range(n))\n",
    "    invalid_medoid_inds = set([])\n",
    "    rs,cs = np.where(D==0)\n",
    "    # the rows, cols must be shuffled because we will keep the first duplicate below\n",
    "    index_shuf = list(range(len(rs)))\n",
    "    wikwik = np.random.shuffle(index_shuf)\n",
    "#     print (wikwik)\n",
    "    np.random.shuffle(index_shuf)\n",
    "    rs = rs[index_shuf]\n",
    "    cs = cs[index_shuf]\n",
    "    for r,c in zip(rs,cs):\n",
    "        # if there are two points with a distance of 0...\n",
    "        # keep the first one for cluster init\n",
    "        if r < c and r not in invalid_medoid_inds:\n",
    "            invalid_medoid_inds.add(c)\n",
    "    valid_medoid_inds = list(valid_medoid_inds - invalid_medoid_inds)\n",
    "\n",
    "    if k > len(valid_medoid_inds):\n",
    "        raise Exception('too many medoids (after removing {} duplicate points)'.format(\n",
    "            len(invalid_medoid_inds)))\n",
    "\n",
    "    # randomly initialize an array of k medoid indices\n",
    "    M = np.array(valid_medoid_inds)\n",
    "    np.random.shuffle(M)\n",
    "    M = np.sort(M[:k])\n",
    "    print(M)\n",
    "\n",
    "    # create a copy of the array of medoid indices\n",
    "    Mnew = np.copy(M)\n",
    "\n",
    "    # initialize a dictionary to represent clusters\n",
    "    C = {}\n",
    "    for t in range(tmax):\n",
    "        # determine clusters, i. e. arrays of data indices\n",
    "        J = np.argmin(D[:,M], axis=1)\n",
    "        for kappa in range(k):\n",
    "            C[kappa] = np.where(J==kappa)[0]\n",
    "        # update cluster medoids\n",
    "        for kappa in range(k):\n",
    "            J = np.mean(D[np.ix_(C[kappa],C[kappa])],axis=1)\n",
    "            j = np.argmin(J)\n",
    "            Mnew[kappa] = C[kappa][j]\n",
    "        np.sort(Mnew)\n",
    "        # check for convergence\n",
    "        if np.array_equal(M, Mnew):\n",
    "            break\n",
    "        M = np.copy(Mnew)\n",
    "    else:\n",
    "        # final update of cluster memberships\n",
    "        J = np.argmin(D[:,M], axis=1)\n",
    "        for kappa in range(k):\n",
    "            C[kappa] = np.where(J==kappa)[0]\n",
    "\n",
    "    # return results\n",
    "    return M, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4 10]\n",
      "medoids:\n",
      "[0.    1.    0.    0.    0.217 0.    0.27  0.183 0.135 0.    0.   ]\n",
      "[0.    0.    0.    0.    0.099 1.    0.    0.    0.246 0.289 0.   ]\n",
      "[1.    0.    0.    0.211 0.    0.    0.095 0.129 0.    0.    0.085]\n",
      "[0.095 0.27  0.    0.101 0.366 0.    1.    0.369 0.    0.    0.   ]\n",
      "[0.    0.    1.    0.    0.086 0.    0.    0.144 0.107 0.125 0.   ]\n",
      "\n",
      "clustering result:\n",
      "label 0:　[0.    1.    0.    0.    0.217 0.    0.27  0.183 0.135 0.    0.   ]\n",
      "label 1:　[0.    0.    0.    0.    0.099 1.    0.    0.    0.246 0.289 0.   ]\n",
      "label 1:　[0.    0.135 0.107 0.    0.073 0.246 0.    0.    1.    0.107 0.   ]\n",
      "label 1:　[0.    0.    0.125 0.    0.086 0.289 0.    0.144 0.107 1.    0.   ]\n",
      "label 2:　[1.    0.    0.    0.211 0.    0.    0.095 0.129 0.    0.    0.085]\n",
      "label 2:　[0.211 0.    0.    1.    0.081 0.    0.101 0.    0.    0.    0.   ]\n",
      "label 2:　[0.085 0.    0.    0.    0.    0.    0.    0.    0.    0.    1.   ]\n",
      "label 3:　[0.    0.217 0.086 0.081 1.    0.099 0.366 0.297 0.073 0.086 0.   ]\n",
      "label 3:　[0.095 0.27  0.    0.101 0.366 0.    1.    0.369 0.    0.    0.   ]\n",
      "label 3:　[0.129 0.183 0.144 0.    0.297 0.    0.369 1.    0.    0.144 0.   ]\n",
      "label 4:　[0.    0.    1.    0.    0.086 0.    0.    0.144 0.107 0.125 0.   ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import numpy as np\n",
    "\n",
    "# import kmedoids\n",
    "\n",
    "# 3 points in dataset\n",
    "data = np.array(titles_score)\n",
    "\n",
    "# distance matrix\n",
    "D = pairwise_distances(data, metric='euclidean')\n",
    "\n",
    "# split into 2 clusters\n",
    "M, C = kMedoids(D, 5)\n",
    "\n",
    "print('medoids:')\n",
    "for point_idx in M:\n",
    "    print( data[point_idx] )\n",
    "hasil =[]\n",
    "print('')\n",
    "print('clustering result:')\n",
    "for label in C:\n",
    "    for point_idx in C[label]:\n",
    "        print('label {0}:　{1}'.format(label, data[point_idx]))\n",
    "        hasil.append({'label':label, 'skor': list(data[point_idx])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'judul': 'Penerapan antarmuka bahasa alami dalam pencarian informasi skripsi pada suatu program studi ',\n",
       "  'skor': [1.0, 0.0, 0.0, 0.211, 0.0, 0.0, 0.095, 0.129, 0.0, 0.0, 0.085],\n",
       "  'id': 0},\n",
       " {'judul': 'System reminder aktifitas akademik dosen ',\n",
       "  'skor': [0.0, 1.0, 0.0, 0.0, 0.217, 0.0, 0.27, 0.183, 0.135, 0.0, 0.0],\n",
       "  'id': 1},\n",
       " {'judul': 'Perancangan Sistem Test Komputerisasi dan Pendukung Keputusan Penerimaan Pegawai',\n",
       "  'skor': [0.0, 0.0, 1.0, 0.0, 0.086, 0.0, 0.0, 0.144, 0.107, 0.125, 0.0],\n",
       "  'id': 2},\n",
       " {'judul': 'Pengolahan Bahasa Alami pada Agen Cerdas Alat Bantu Konsultasi Zakat',\n",
       "  'skor': [0.211, 0.0, 0.0, 1.0, 0.081, 0.0, 0.101, 0.0, 0.0, 0.0, 0.0],\n",
       "  'id': 3},\n",
       " {'judul': 'Perancangan dan implementasi system pengenalan  jenis kulit hewan unutk kerajinan kulit berbasis system cerdas ',\n",
       "  'skor': [0.0,\n",
       "   0.217,\n",
       "   0.086,\n",
       "   0.081,\n",
       "   1.0,\n",
       "   0.099,\n",
       "   0.366,\n",
       "   0.297,\n",
       "   0.073,\n",
       "   0.086,\n",
       "   0.0],\n",
       "  'id': 4},\n",
       " {'judul': 'Pengembangan Template Media Pembelajaran Berbasis Flash',\n",
       "  'skor': [0.0, 0.0, 0.0, 0.0, 0.099, 1.0, 0.0, 0.0, 0.246, 0.289, 0.0],\n",
       "  'id': 5},\n",
       " {'judul': 'Membangun system informasi eksekutif (SIE) dengan menggunakan pendekatan system cerdas ',\n",
       "  'skor': [0.095, 0.27, 0.0, 0.101, 0.366, 0.0, 1.0, 0.369, 0.0, 0.0, 0.0],\n",
       "  'id': 6},\n",
       " {'judul': 'Perancangan visualisasi informasi untuk system evaluasi guru ',\n",
       "  'skor': [0.129, 0.183, 0.144, 0.0, 0.297, 0.0, 0.369, 1.0, 0.0, 0.144, 0.0],\n",
       "  'id': 7},\n",
       " {'judul': 'Pengembangan Sistem Penilaian Kerja Dosen dengan Aspek IKD dan SKP 2014 Berbasis Online',\n",
       "  'skor': [0.0, 0.135, 0.107, 0.0, 0.073, 0.246, 0.0, 0.0, 1.0, 0.107, 0.0],\n",
       "  'id': 8},\n",
       " {'judul': 'Perancangan animasi wayang  pendidikan sebagai pengembangan media edukasi sekolah ',\n",
       "  'skor': [0.0, 0.0, 0.125, 0.0, 0.086, 0.289, 0.0, 0.144, 0.107, 1.0, 0.0],\n",
       "  'id': 9},\n",
       " {'judul': 'Studi Deskriptif: Penyebab dan Bentuk Perilaku Mencontek pada SMP Muhammadiyah se-Kota Yogyakarta Tahun 2012/2013',\n",
       "  'skor': [0.085, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       "  'id': 10}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kumpul = []\n",
    "for i in range(0,len(data)):\n",
    "    kumpul.append({'judul':list_judul[i],'skor':list(titles_score[i]), 'id': i})\n",
    "kumpul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Penerapan antarmuka bahasa alami dalam pencarian informasi skripsi pada suatu program studi  2\n",
      "0 System reminder aktifitas akademik dosen  0\n",
      "10 Perancangan Sistem Test Komputerisasi dan Pendukung Keputusan Penerimaan Pegawai 4\n",
      "5 Pengolahan Bahasa Alami pada Agen Cerdas Alat Bantu Konsultasi Zakat 2\n",
      "7 Perancangan dan implementasi system pengenalan  jenis kulit hewan unutk kerajinan kulit berbasis system cerdas  3\n",
      "1 Pengembangan Template Media Pembelajaran Berbasis Flash 1\n",
      "8 Membangun system informasi eksekutif (SIE) dengan menggunakan pendekatan system cerdas  3\n",
      "9 Perancangan visualisasi informasi untuk system evaluasi guru  3\n",
      "2 Pengembangan Sistem Penilaian Kerja Dosen dengan Aspek IKD dan SKP 2014 Berbasis Online 1\n",
      "3 Perancangan animasi wayang  pendidikan sebagai pengembangan media edukasi sekolah  1\n",
      "6 Studi Deskriptif: Penyebab dan Bentuk Perilaku Mencontek pada SMP Muhammadiyah se-Kota Yogyakarta Tahun 2012/2013 2\n"
     ]
    }
   ],
   "source": [
    "fix_data = []\n",
    "for i in range(0,len(kumpul)):\n",
    "    for j in range(0,len(hasil)):\n",
    "        if kumpul[i]['skor'] == hasil[j]['skor']:\n",
    "            print(j,kumpul[i]['judul'],hasil[j]['label'])\n",
    "            fix_data.append({'id':j,'judul':kumpul[i]['judul'],'cluster':hasil[j]['label']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot([4,8,13,17,20],[54, 67, 98, 78, 45])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = [2,4,6,7,9,13,19,26,29,31,36,40,48,51,57,67,69,71,78,88]\n",
    "y = [54,72,43,2,8,98,109,5,35,28,48,83,94,84,73,11,464,75,200,54]\n",
    "plt.scatter(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
